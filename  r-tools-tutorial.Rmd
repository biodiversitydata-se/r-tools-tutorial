---
title: "Tutorial for using SBDI4R for analysis of biodiversity primary data"
author: "Debora Arlt, Alejandro Ruete and Charles Campbell for the Swedish Biodiversity Data Infrastructure" 
date: "`r Sys.Date()`"
description: "A set of examples for using SBDI4R" 
output: bookdown::gitbook
site: bookdown::bookdown_site
documentclass: book
bibliography:
- references.bib
biblio-style: apalike
link-citations: yes
colorlinks: yes
graphics: yes
lot: yes
lof: yes
fontsize: 11pt
mainfont: Palatino
monofont: "Source Code Pro"
monofontoptions: "Scale=0.8"
github-repo: https://github.com/biodiversitydata-se/r-tools-tutorial
cover-image: images/SBDI.png
---
```{r include=FALSE, cache=FALSE}
knitr::opts_knit$set(root.dir = here::here())
set.seed(1)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = FALSE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  out.width = "\\textwidth", 
  fig.align = "center",
  fig.width = 7,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)
options(knitr.kable.NA = "")
options(dplyr.print_min = 6, dplyr.print_max = 6)
```

```{r setup, include=FALSE}
options(
  htmltools.dir.version = FALSE, formatR.indent = 2,
  width = 55, digits = 4, warnPartialMatchAttr = FALSE,
  warnPartialMatchDollar = FALSE
)

lapply(c('xfun'), function(pkg) {
  if (system.file(package = pkg) == '') install.packages(pkg)
})
```

# Introduction **{-}**

[TO BE UPDATED] Each research question draws its own challenges which are unique in themselves. Our aim here is to provide a workflow which answers and / or prompts the large scale questions that should be asked at each stage of the process. We point to resources, methods and facilities that may be useful in answering a particular question. We assume some knowledge of statistical inference and it limitations. The validity and appropriateness of a particular method is dependent on the individual researcher(s). This workflow is focused on the statistical programming language R, as an environment where the complete analysis workflow can take place and can be documented in a fully reproducible way. However, we also point to other tools that can be used at different stages, and ways to import and export the data from and to those tools.

Biodiversity resources are increasingly international. We focus on biodiversity data and resources from Sweden but our aim is to present considerations and methods that can be applied beyond Sweden's borders.

General description of the workflow here. Data--\>Cleaning--\>Fitness evaluation--\>Analysis always exploring and filtering the data in light of the research question. Also say here that if known from before, the cleaning and filtering criteria can be set directly on the query!

`r htmltools::includeHTML("images/Workflow Overview Horizontal.html")`

The SBDI4R package is primarily for accessing data. It includes some filter functions that allow you to filter prior to download. It also includes some simple summary functions, and some function for some simple data exploration. The examples also show you how you can use the data by continued exploring and analysing using other R package.

Please get in contact with us if you have questions regarding the use of the SBDI4R package.

## Using SBDI4R

Lets assume you have already installed the package as shown in the main site \url{https://biodiversitydata-se.github.io/SBDI4R}.

The SBDI4R package must be loaded for each new R session:

```{r, message=FALSE}
library(SBDI4R)
sbdi_config(caching="off")
```

However, the options you stored in .Rprofile if you did it so, will load automatically with the package.

Then, check that we have some additional packages that we'll use in the examples, and install them if necessary.

```{r, message=FALSE}
to_install <- c("ape", "dplyr", "ggplot2", "jpeg", "leaflet","maps", "mapdata",
                "maptools", "phytools", "sp", "rgeos", "tidyr", "vegan")
to_install <- to_install[!sapply(to_install, requireNamespace, quietly=TRUE)]
if(length(to_install)>0)
    install.packages(to_install, repos="http://cran.us.r-project.org")
```

<!--chapter:end:index.Rmd-->

---
editor_options: 
  markdown: 
    wrap: 72
---
```{r include=FALSE, cache=FALSE}
knitr::opts_knit$set(root.dir = here::here())
set.seed(1)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = FALSE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  out.width = "\\textwidth", 
  fig.align = "center",
  fig.width = 7,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)
options(knitr.kable.NA = "")
options(dplyr.print_min = 6, dplyr.print_max = 6)
```

# Example with Fish data from XXX

```{r setup2, include = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(width = 120)
```

Here we provide a collection of use-examples showing examples for a
range of queries that we think a typical use of the biodiversity
infrastructure may want to perform.

## Example 1: Name searching and taxonomic trees

We want to look at the taxonomy of titmice, but we don't know what the
correct scientific name is, so let's search for it:

```{r, warning=FALSE, message=FALSE}
sx <- search_fulltext("parus")
sx$data[,c( "name","species", "speciesGuid", "rank")]
```

But we see some e.g. insects (**Neuroctenus parus**) are also returned.
We want to restrict the search to Paridae.

```{r, message=FALSE}
sx <- search_fulltext("parus", fq="family_s:Paridae")
sx$data[,c( "name","species", "speciesGuid", "rank")]
```

To restrict the query specifically to birds we can also use the 'fq'
argument to filter the query (see
\code{sbdi_fields("general", as_is=TRUE)} for all the fields that are
queryable), and increase page_size to include more records (default=10):

```{r, message=FALSE}
sx <- search_fulltext("parus", fq="class_s:Aves", page_size=100)
head(sx$data[,c( "name","species", "speciesGuid", "rank")])
```

Now we can download the taxonomic data (note that the search is
case-sensitive):

```{r, message=FALSE, results=FALSE}
tx <- taxinfo_download("family_s:Paridae", 
                       fields=c("guid", "genus_s", "scientificName", "rank"), 
                       verbose = FALSE)
tx <- tx[tx$rank == "species",] ## restrict to species
```

We can make a taxonomic tree plot using the `phytools` package:

```{r, message=FALSE}
library(phytools)
## as.phylo requires the taxonomic columns to be factors
tx$genusS <- as.factor(tx$genusS)
tx$scientificName <- as.factor(tx$scientificName)
## create phylo object of Scientific.Name nested within Genus
ax <- as.phylo(~genusS/scientificName, data=tx)
plotTree(ax, fsize=0.7, ftype="i") ## plot it
```

## Example 2: Get some data, filter the search, get quality assertions, plotting data on a map and save data

Download occurrence data for the "Sommarlånke" and view top of the data
table:

```{r, message=FALSE, eval=FALSE}
x <- occurrences(taxon="Callitriche cophocarpa",
                 email="test@test.org", 
                 download_reason_id=10)
head(x$data)
table(x$data$dataResourceName)
```

Similarly, we could search by common names

```{r, message=FALSE, eval=FALSE }
x <- occurrences(taxon="sommarlånke",
                 email="test@test.org", 
                 download_reason_id=10, 
                 verbose = FALSE)
head(x$data)
table(x$data$dataResourceName)
```

if you get to know what you are doing you could search a batch of
species (only scientific names so far)...

```{r, message=FALSE }
taxa <- c("Callitriche", "Anarrhinum")
fq_str <- paste0("raw_name:&quot;", taxa, "&quot;")
fq_str <- paste0(fq_str, collapse = " OR ")
xbatch <- occurrences(fq=fq_str, 
                 email="test@test.org", 
                 download_reason_id=10, 
                 verbose = FALSE)
head(xbatch$data)
table(xbatch$data$dataResourceName)
table(xbatch$data$basisOfRecord)
```

### Search filters

We see there are different data sources. Let´s assume you only need to
see data from one source, e.g. Artportalen. If you see on the data that
Artportalen's identifier is "dr5" you can directly filter the search by:

```{r, message=FALSE}
xf <- occurrences(taxon="Callitriche cophocarpa", 
                 fq = "data_resource_uid:dr5",
                 email="test@test.org", 
                 download_reason_id=10, verbose = FALSE)
table(xf$data$dataResourceName)
```

Else, you can search available data resources, collections (and more)
using the interactive function \code{pick_filter}. The
\code{pick_filter}function lets you explore data collections, spatial
layers, and soon more indexed fields.

```{r, message=FALSE, eval= FALSE}
fq_str <- pick_filter("resource") 
## follow the instructions

xf <- occurrences(taxon="Callitriche cophocarpa", 
                 fq = fq_str,
                 email="test@test.org", 
                 download_reason_id=10)
```

In the same way you can use the spatial layers that are available to
spatially search for the indexed observations.

```{r, message=FALSE, eval= FALSE}
# fq_str <- pick_filter("layer") 
# Follow the instructions, but here we just use the county Uppsala
fq_str <- "cl10097:Uppsala"

xf <- occurrences(taxon="Callitriche cophocarpa", 
                 fq = fq_str,
                 email="test@test.org", 
                 download_reason_id=10)
```

Note that this is fundamentally different than filtering by
\dQuote{county:Uppsala} as this will search for the text
\dQuote{uppsala} in the field \dQuote{county}, rather than spatially
matching the observations.

### Other filters on queries

Any search could be filtered by any indexed field (a.k.a. column or
variable). You can find which are the variables that are indexed with
the command \`c These filter strings require SOLR syntax, see
[SOLR](https://blog.imaginea.com/solr-query-equivalent-to-the-database-query/)
For example, let's filter observations with coordinate uncertainty
smaller than or equal to 100 m.

```{r, message=FALSE}
xf <- occurrences(taxon="Callitriche cophocarpa", 
                 fq="coordinate_uncertainty:[0 TO 100]",
                 email="test@test.org", 
                 download_reason_id=10)

range(xf$data$coordinateUncertaintyInMetres)
```

<!-- or being reported as within a a county (Note: this is what the observer says) -->

<!-- ```{r} -->

<!-- xf <- occurrences(taxon="Callitriche cophocarpa", -->

<!--                  fq="county:Uppsala", -->

<!--                  email="test@test.org", -->

<!--                  download_reason_id=10) -->

<!-- ``` -->

One could search for observation in specific years:

```{r, message=FALSE}
# year = 2019
x2019 <- occurrences(taxon="Reynoutria japonica", 
                     fq="year:2019",
                     email="test@test.org", 
                     download_reason_id=10)
nrow(x2019$data)

x2yr <- occurrences(taxon="Reynoutria japonica", 
                    fq=c("year:2018 OR year:2019"),
                    email="test@test.org", 
                    download_reason_id=10)
nrow(x2yr$data)
```

In the same way, one could search for observations *between* two years:

```{r, message=FALSE}
xf <- occurrences(taxon="Callitriche cophocarpa", 
                 fq="year:[2010 TO 2020]",
                 email="test@test.org", 
                 download_reason_id=10)

hist(xf$data$year, xlab = "Year", main = "")
```

Likewise, search conditions can be accumulated and will be treated as
AND conditions:

```{r, message=FALSE}
xf <- occurrences(taxon="Callitriche cophocarpa", 
                 fq=c("year:[2010 TO 2020]", "month:[06 TO 08]"),
                 email="test@test.org", 
                 download_reason_id=10)

hist(xf$data$year, xlab = "Year", main = "")
```

or, occurrences could be filtered by the basis of record:

```{r, message=FALSE}
xf <- occurrences(taxon="Callitriche cophocarpa", 
                 fq="basis_of_record:HumanObservation",
                 email="test@test.org", 
                 download_reason_id=10)

unique(xf$data$basisOfRecord)
```

### Quality assertions

Data quality assertions are a suite of fields that are the result of a
set of tests performed on data. We continue using the data for the
Blunt-fruited Water-starwort and get a summary of the data quality
assertions:

```{r, message=FALSE}
x <- occurrences(taxon="Callitriche cophocarpa",
                 fq = "data_resource_uid:dr5",
                 email="test@test.org",
                 download_reason_id=10, 
                 verbose = FALSE)
summary(x)
```

You can see a list of all record issues using
`sbdi_fields("assertions")` and see what is considered as fatal quality
issues.

```{r}
assert <- sbdi_fields("assertions")
assertFatal <- assert[assert$isFatal==TRUE,"name"]
wAssertInX <- assertFatal %in% colnames(x$data)
colSums(x$data[,assertFatal[wAssertInX]])
```

### Plotting data on a map

You can quickly plot all the observations with the function
`ocurrence_plot()`, here we specify to map all 'error' issues:

```{r, eval=FALSE}
occurrences_plot(x, "obsPlot.pdf", qa="error", 
                  grouped=FALSE, taxon_level="species", 
                  pch='+')
```

Note that the plot is saved to a pdf file in the current working
directory. You can find that by `getwd()`.

<!-- <img src='https://github.com/biodiversitydata-se/SBDI4R/blob/master/man/figures/obsPlot_CallitricheCophocarpa.pdf' /> -->

<img src="https://raw.githubusercontent.com/biodiversitydata-se/SBDI4R/2fe8a0223a293e4ef3d91bfb963531402319c985/man/figures/obsPlot_CallitricheCophocarpa.pdf"/>

There are many other ways of producing spatial plots in R. The `leaflet`
package provides a simple method of producing browser-based maps with
panning, zooming, and background layers:

```{r, message=FALSE}
library(leaflet)
## drop any records with missing lat/lon values
x$data <- x$data[!is.na(x$data$longitude) & !is.na(x$data$latitude),] 
xa <- check_assertions(x)
## columns of x corresponding to a fatal assertion
x_afcols <- which(names(x$data) %in% xa$occurColnames)
## rows of x that have a fatal assertion
x_afrows <- apply(x$data[,x_afcols], 1, any)
## which taxonIdentificationIssue assertions are present in this data?
these_assertions <- names(x$data)[x_afcols]
## make a link to the web page for each occurrence
popup_link <- paste0("<a href=\"https://records.bioatlas.se/occurrences/",
                      x$data$id,"\">Link to occurrence record</a>")
## colour palette
pal <- c(sub("FF$","", heat.colors(length(these_assertions))))
## map each data row to colour, depending on its assertions
marker_colour <- rep("#00FF00", nrow(x$data))
if(length(these_assertions)>0){
  for (k in 1:length(these_assertions)){
    marker_colour[x$data[,x_afcols[k]]] <- pal[k]
  } 
}

## blank map, with imagery background
m <- addProviderTiles(leaflet(),"Esri.WorldImagery") %>% 
  ## add markers
  addCircleMarkers(x$data$longitude, x$data$latitude,  
                   radius = 2, fillOpacity =.5, opacity = 1,
                   col=marker_colour, popup=popup_link) %>% 
  addLegend(colors = pal, opacity = 1, labels = these_assertions)
m
```

### Save data

```{r}
# save as data.frame
Callitriche <- as.data.frame(x$data)

# simplyfy data frame
calli <- data.frame(Callitriche$scientificName,
                   Callitriche$latitude,
                   Callitriche$longitude)
# simplify column names
colnames(calli) <- c("species","latitude","longitude")
# remove rows with missing values (NAs)
calli <- na.omit(calli)

# save new dataframe
write.csv(calli,"Callitriche.csv")
```

## Example 3: Summarise occurrences over a defined grid

Now, following with the data downloaded in the previous example, we want
to summarise occurrences over a defined grid instead of plotting every
observation point. First we need to overlay the observations with the
grid. In this case, the standard Swedish grids at 50, 25, 10 and 5 km
are provided as data (with Coordinate Reference System = WGS84,
EPSG:4326).

```{r, message=FALSE, warning=FALSE}

x <- occurrences(taxon="Callitriche cophocarpa",
                 fq = "data_resource_uid:dr5",
                 email="test@test.org",
                 download_reason_id=10, 
                 verbose = FALSE)

library(sp) # the function coordinates() and proj4string() are in sp
library(rgeos) #  the function over() is in package rgeos
# load some shapes over Sweden
# Political borders
data("swe_wgs84", package="SBDI4R", envir=environment()) 
# A standard 50km grid
data("Sweden_Grid_50km_Wgs84", package="SBDI4R", envir=environment()) 

grid <- Sweden_Grid_50km_Wgs84
grid <- spTransform(grid, CRS("+init=epsg:4326")) ## it has the same CRS 
# but changes are undergoing in the sp package and this step is needed

# make the observations spatial
# NOTE: make sure there are no NAs on either column defining the coordinates 
# see example 2 for cleaning your dataset.

obs <- as.data.frame(x$data)
coordinates(obs) <- obs[,c("longitude","latitude")]
proj4string(obs) <- CRS("+init=epsg:4326")

nObs <- nrow(obs)

## overlay the data with the grid
ObsInGridList <- over(grid, obs, returnList=TRUE)
wNonEmpty <- unname( which( unlist(lapply(ObsInGridList, nrow)) != 0) )
if(length(wNonEmpty)==0) message("Observations don't overlap any grid cell.")

## check nObs
nObsInGrid <- sum(unlist(lapply(ObsInGridList, nrow)))
```

The result 'ObsInGridList' is a 'list' object with a subset of the data
on each grid.

### Summarise

Now summarise occurrences within grid cells:

```{r}
## apply a summary over the grid
nCells <- length(ObsInGridList)

res <- data.frame("nObs"=as.numeric(rep(NA,nCells)),
                  "nYears"=as.numeric(rep(NA,nCells)),
                  stringsAsFactors = FALSE)

cols2use <- c("scientificName", "year")

dataRes <- lapply(ObsInGridList[wNonEmpty], function(x){
  x <- x[,cols2use]
  colnames(x) <- c("scientificName", "year")
  
  return(c("nObs" = length(x[,"scientificName"]),
           "nYears" = length(unique(x[,"year"]))
  ))
})

dataRes <- data.frame(matrix(unlist(dataRes),
                             nrow=length(dataRes), 
                             byrow=TRUE),
                    stringsAsFactors = FALSE)

dataRes$X1 <- as.numeric(dataRes$X1)
dataRes$X2 <- as.numeric(dataRes$X2)

res[wNonEmpty,] <- dataRes
rownames(res) <- row.names(grid)

resSp <- sp::SpatialPolygonsDataFrame(grid, res)
```

### Plotting data on a map

Finally plot the grid summary as a map:

```{r grid, warning=FALSE, fig.width=6, fig.height=6, message=FALSE}
palBW <- leaflet::colorNumeric(c("white", "navyblue"), 
                               c(0, max(resSp@data$nObs, na.rm = TRUE)), 
                               na.color = "transparent")
oldpar <- par()
par(mar = c(1,1,0,0))
plot(resSp, col=palBW(resSp@data$nObs), border = NA)
plot(swe_wgs84$Border, border=1, lwd=1, add=T)
legend("bottomleft", 
       legend = round(seq(0, max(resSp@data$nObs, na.rm = TRUE), length.out = 5)),
       col = palBW(seq(0, max(resSp@data$nObs, na.rm = TRUE), length.out = 5)),
       title = "Number of \nobservations", pch = 15, bty="n")
par(oldpar)
```

### Other polygons

Any other set of polygons could also be used to summarise, for example,
the counties.

```{r, message=FALSE, warning=FALSE}
counties <- swe_wgs84$Counties
## again, even both the obs and the polygon have the same CRS 
## changes are undergoing in the sp package and this step is needed
counties <- spTransform(counties, CRS("+init=epsg:4326")) 

## overlay the data with the counties
ObsInCountyList <- over(counties, obs, returnList=TRUE)
wNonEmpty <- unname( which( unlist(lapply(ObsInCountyList, nrow)) != 0) )
if(length(wNonEmpty)==0) message("Observations don't overlap any grid cell.")

## check nObs
nObsInCounty <- sum(unlist(lapply(ObsInCountyList, nrow)))

## apply a summary over the grid
nCells <- length(ObsInCountyList)

res <- data.frame("nObs"=as.numeric(rep(NA,nCells)),
                  "nYears"=as.numeric(rep(NA,nCells)),
                  stringsAsFactors = FALSE)

cols2use <- c("scientificName", "year")

dataRes <- lapply(ObsInCountyList[wNonEmpty], function(x){
  x <- x[,cols2use]
  colnames(x) <- c("scientificName", "year")
  
  return(c("nObs" = length(x[,"scientificName"]),
           "nYears" = length(unique(x[,"year"]))
  ))
})

dataRes <- data.frame(matrix(unlist(dataRes),
                             nrow=length(dataRes), 
                             byrow=TRUE),
                    stringsAsFactors = FALSE)

dataRes$X1 <- as.numeric(dataRes$X1)
dataRes$X2 <- as.numeric(dataRes$X2)

res[wNonEmpty,] <- dataRes
rownames(res) <- row.names(counties)

resSp <- sp::SpatialPolygonsDataFrame(counties, res)
```

and again plotting as a map:

```{r counties, warning=FALSE, fig.width=6, fig.height=6}
palBW <- leaflet::colorNumeric(c("white", "navyblue"), 
                               c(0, max(resSp@data$nObs, na.rm = TRUE)), 
                               na.color = "transparent")
oldpar <- par()
par(mar = c(1,1,0,0))
plot(resSp, col=palBW(resSp@data$nObs), border = NA)
plot(swe_wgs84$Border, border=1, lwd=1, add=T)
text(coordinates(counties), as.character(counties$LnNamn), font = 2, cex=.5 )
legend("bottomleft", 
       legend = round(seq(0, max(resSp@data$nObs, na.rm = TRUE), length.out = 5)),
       col = palBW(seq(0, max(resSp@data$nObs, na.rm = TRUE), length.out = 5)),
       title = "Number of \nobservations", pch = 15, bty="n")
par(oldpar)
```

### Add the county name to each observation

```{r, results=FALSE, warning=FALSE}
countiesLab <- as.character(counties$LnNamn)

## Add a column to the obs data.frame to hold the id of the overlapped polygon, 
## in this case, Län (county)
obs$overId <- NA 

for(c in 1:length(ObsInCountyList)){
  if(nrow(ObsInCountyList[[c]]) > 0){
    idsC <- ObsInCountyList[[c]]$id
    wObs <- match(idsC, obs$id)
    obs$overId[wObs] <- rep(countiesLab[c], length(wObs))
  }
  print(countiesLab[c])
}

# check if there are any observation that doesn't fall into the territory of any county
obs[which(is.na(obs$overId)),]

oldpar <- par()
par(mar = c(1,1,0,0))
plot(counties, border=1, lwd=1)
plot(obs[which(is.na(obs$overId)),], pch=19, cex=.5, col="red", add=T)
par(oldpar)
```

It is clear from this image that there are observations outside the
territorial extent of the county but that may be within the counties
water bodies or coastal areas.

## Example 4: Area search and report. What listed species exist in a given area?

Vector spatial layers (eg. Polygons) can be imported in a number of
different ways. Bioatlas' APIs take as search input polygons in the s.k.
WKT (Well Known Text
\url{https://www.geoapi.org/3.0/javadoc/org/opengis/referencing/doc-files/WKT.html}).
So the first step is to load a vector layer and transform it into a WKT
string. First download a .zip file with different delimitations for
Sweden
\url{https://www.scb.se/hitta-statistik/regional-statistik-och-kartor/regionala-indelningar/digitala-granser}
and move it somewhere you like in your computer. We recommend you move
it into your working directory (\code{getwd()}). Extract the .zip file
named KommunSweref99.zip.
<!-- We use the ALA4R's caching mechanism here, but you could equally download this file directly. -->

```{r, eval=FALSE}
library(rgdal)
shape <- readOGR(dsn=file.path("your/path/to/file", "Kommun_Sweref99TM_region.shp"))
```

This will only work when you set a valid filepath, and will create an
object of class SpatialPolygon. You could instead use the data we kindly
provided in this package \code{data("swe")}

```{r}
shape <- swe$Municipalities
## extract just the Municipality of Örebro
shape <- shape[shape$KnNamn=="Örebro", ]
```

We could create the WKT string using the `rgeos` library:

```{r, eval=FALSE}
library(rgeos)
wkt <- writeWKT(shape)
```

Unfortunately, in this instance this gives a WKT string that is too long
and won't be accepted by the web service. Also, the shapefile we just
got is projected in the coordinate system SWEREF99 TM, and the web
service only accepts coordinates in a geodesic coordinate system WGS84.
Instead, let's construct the WKT string directly, which gives us a
little more control over its format:

```{r, warning=FALSE}
library(sp)
shape <- spTransform(shape, CRSobj = CRS("+init=epsg:4326")) ## the magic number for WGS84
lonlat <- shape@polygons[[1]]@Polygons[[1]]@coords ## extract the polygon coordinates
## extract the convex hull of the polygon to reduce the length of the WKT string
temp <- chull(lonlat)
lonlat <- lonlat[c(temp, temp[1]), ]
## create WKT string
## first join each lon-lat coordinate pair
temp <- apply(lonlat, 1, function(z) paste(z, collapse=" "))
## now build the WKT string
wkt <- paste("POLYGON((", paste(temp, collapse=","), "))", sep="")
```

Now extract the species list in this polygon:

```{r eval=FALSE}
species_list(wkt=wkt, fq="rank:species") %>%
    dplyr::arrange(desc(occurrenceCount)) %>%
    dplyr::select(speciesName, species, family, occurrenceCount) %>%
    head(10)
```

```{r message=FALSE, echo=FALSE}
tryCatch({
  species_list(wkt=wkt, fq="rank:species") %>%
      dplyr::arrange(desc(occurrenceCount)) %>%
      dplyr::select(speciesName, species, family, occurrenceCount) %>%
      head(20)
}, error = function(e) { print(e$message)})
```

## Example 5: Community composition and turnover

```{r message=FALSE, warning=FALSE}
library(vegan)
```

Define our area of interest as a transect running westwards from the
Stockholm region, and download the occurrences of legumes (Fabaceae; a
large family of flowering plants) in this area:

```{r eval=FALSE}
## A rough polygon aroun the Mällardalen
wkt <- "MULTIPOLYGON(((14.94 58.88, 14.94 59.69, 18.92 59.69, 18.92 58.88, 14.94 58.88)))"

## define some environmental layers of interest [see sbdi_fields(fields_type = "occurrence")]
# el10011 https://spatial.bioatlas.se/ws/layers/view/more/worldclim_bio_12
# el10009 https://spatial.bioatlas.se/ws/layers/view/more/worldclim_bio_10
env_layers <- c("el10009","el10011") 

## Download the data.  We use the `occurrences()` function, adding environmental
## data via the 'extra' parameter. 
x <- occurrences(fq="family:Fabaceae", 
                 wkt=wkt, qa="none",
                 download_reason_id="testing", 
                 extra=env_layers)
```

Convert this to a sites-by-species data.frame:

```{r, eval=FALSE}
library(dplyr)
library(tidyr)
xgridded <- x$data %>%
    ## discard genus- and higher-level records
    filter(rank %in%
                  c("species", "subspecies", "variety", "form", "cultivar")) %>%
    ## bin into 0.5-degree bins
    mutate(longitude=round(longitude*2)/2, 
           latitude=round(latitude*2)/2, 
           worldClimMeanTemperatureOfWarmestQuarter = worldClimMeanTemperatureOfWarmestQuarter /10) %>%
    ## average environmental vars within each bin
    group_by(longitude,latitude) %>%
    mutate(worldClimAnnualPrecipitation = mean(worldClimAnnualPrecipitation, na.rm=TRUE),
           worldClimMeanTemperatureOfWarmestQuarter = mean(worldClimMeanTemperatureOfWarmestQuarter, na.rm=TRUE)) %>%
    ## subset to vars of interest
    select(longitude, latitude, species, 
                  worldClimAnnualPrecipitation,
                  worldClimMeanTemperatureOfWarmestQuarter) %>%
    ## take one row per cell per species (presence)
    distinct() %>%
    ## calculate species richness
    mutate(richness=n()) %>%
    ## convert to wide format (sites by species)
    mutate(present=1) %>%
    do(tidyr::spread(data=., key=species, value=present, fill=0)) %>%
    ungroup()
## where a species was not present, it will have NA: convert these to 0
sppcols <- setdiff(names(xgridded),
                   c("longitude", "latitude", 
                     "worldClimAnnualPrecipitation", 
                     "worldClimMeanTemperatureOfWarmestQuarter",
                     "richness"))
xgridded <- xgridded %>% 
  mutate_at(sppcols, function(z) ifelse(is.na(z), 0, z))
```

```{r, include=FALSE}
## load data from a local copy so that vignette building doesn't require downloading a big chunk of data and slow sites-by-species processing
## this file generated by running the above unevaluated code blocks, then
## saveRDS(xgridded, file="vignette_fabaceae.rds")
xgridded <- readRDS("vignette_fabaceae.rds")
sppcols <- setdiff(names(xgridded), c("longitude", "latitude", 
                                      "worldClimAnnualPrecipitation", 
                                      "worldClimMeanTemperatureOfWarmestQuarter", 
                                      "richness"))
```

The end result:

```{r, message=FALSE, warning=FALSE}
xgridded[, 1:10]
```

Now we can start to examine the patterns in the data. Let's plot
richness as a function of longitude:

```{r, warning=FALSE}
library(ggplot2)
ggplot(xgridded, aes(longitude, richness)) + 
  geom_point() + 
  theme_bw()
```

<!-- We see outliers in species richness that may be solved if names and synonyms are curated -->

<!-- as.data.frame(xgridded[xgridded$richness>200,]) -->

Species richness as a function of environment:

```{r, warning=FALSE}
ggplot(xgridded, aes(worldClimMeanTemperatureOfWarmestQuarter , 
                     worldClimAnnualPrecipitation, 
                     colour=richness)) +
  scale_colour_distiller(palette="Spectral") +
  geom_point(size=8) + 
  theme_bw()
```

Higher species richness in hottest areas.

How does the community composition change along the transect? Use
clustering:

```{r fig.width=6, fig.height=6}
library(vegan)
## Bray-Curtis dissimilarity
D <- vegdist(xgridded[, sppcols], "bray")
## UPGMA clustering
cl <- hclust(D, method="ave")
## plot the dendrogram
plot(cl)
## extract group labels at the 5-group level
grp <- cutree(cl, 5)
## coalesce small (outlier) groups into a single catch-all group
sing <- which(table(grp)<5)
# grp[grp %in% sing] <- 6 ## put these in a new combined group
grp <- sapply(grp, function(z)which(unique(grp)==z)) ## renumber groups
xgridded$grp <- as.factor(grp)
## plot
## colours for clusters
thiscol <- c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b", 
             "#e377c2", "#7f7f7f", "#bcbd22", "#17becf")
ggplot(xgridded, aes(longitude, latitude, colour=grp)) + 
  geom_point(size=5) +
  scale_colour_manual(values=thiscol) + 
  theme_bw()

## or a slightly nicer map plot
library(maps)
library(mapdata)
map("worldHires", "Sweden", 
    # xlim=c(105, 155), ylim=c(-45, -10), 
    col="gray90", fill=TRUE)
with(xgridded, points(longitude, latitude, 
                      pch=21, col=thiscol[grp], 
                      bg=thiscol[grp], cex=0.75))
```

## Example 6: Handlig data in R after being downloaded

R is pretty powerful when it comes to cleaning, selecting and filtering
data

```{r Datahangling, message=FALSE}
x <- occurrences(taxon="Callitriche cophocarpa",
                  fq = "data_resource_uid:dr5",
                  email="test@test.org",
                  download_reason_id=10, 
                  verbose = FALSE)
#keep spatially unique data at 0.01 degrees (latitude and longitude)
ll001 <- unique(x, spatial=0.01)
summary(ll001)

# #keep only information for which fatal or "error" assertions do not exist
nofat <- subset(x, remove.fatal = TRUE)
summary(nofat)

#keep only observations with a maximum spatial uncertainty of 50m
SpatCert <- subset(x, max.spatial.uncertainty=50)
summary(SpatCert)

# quickly get some more info about the data:
# no. observations (records)
nrow(x$data)
 
# no. obs/year
freq_year <- table(x$data$year)

# no. obs across years:
plot(freq_year, bty="n", ylab="Frequency")
# or
hist(x$data$year, 20)

# Subsetting is done using '[ ]'
x10yr <- x$data[(x$data$year>=2010 & x$data$year<=2019),] 
table(x10yr$year)
```

## Example 7: Aggregating data with 'BIRDS'

[BIRDS](https://greensway.github.io/BIRDS/) is an R package that
provides a set of tools for systematizing biodiversity data review in
order to evaluate whether a set of species observation are fit-for-use
and help take decisions upon its use in further analysis.\
In the following examples you will learn to aggregate statistics over
space and time.

```{r BIRDSspatial, message=FALSE, warning=FALSE}
library(BIRDS)
x <- occurrences(taxon="Callitriche cophocarpa",
                  fq = "data_resource_uid:dr5",
                  email="test@test.org",
                  download_reason_id=10, 
                  verbose = FALSE)
# we need to temporally create fake month data as it is not being retrieved from the database
# x$data$month <- floor(runif(n = nrow(x$data), min = 1, max = 13))
x$data$month <- ifelse(x$data$day==31, 
                       sample(c(1,3,5,7,8,10,12), 1, replace = TRUE),
                       ifelse(x$data$day>=28, 
                              sample(c(1,3:12), 1, replace = TRUE), #not February
                              sample(c(1:12), 1, replace = TRUE)
                              )
                       )

## Define the visit
OB <- organiseBirds(x$data, 
                    sppCol = "scientificName", 
                    idCols = c("locality"), 
                    timeCols = c("year", "month","day"),
                    xyCols = c("longitude", "latitude"))

SB <- summariseBirds(OB, grid = Sweden_Grid_25km_Wgs84)

maxC <- max(SB$spatial@data$nObs, na.rm = TRUE)
palBW <- leaflet::colorNumeric(c("white", "navyblue"), 
                               c(0, maxC), 
                               na.color = "transparent")
oldpar <- par()
par(mar = c(4,0,4,0), mfrow=c(1,3))
plot(SB$spatial, col=palBW(SB$spatial@data$nObs), main="All years") ## with palette
legend("topleft", inset = c(0,0.05),
       legend = round(seq(0, maxC, length.out = 5)),
       col = palBW(seq(0, maxC, length.out = 5)),
       title = "Number of \nobservations", pch = 15, bty="n")

## or export other combinations, e.g. one map per observed year
yearlySp <- exportBirds(SB, 
                        dimension = "spatial", 
                        timeRes = "yearly", 
                        variable = "nObs", 
                        method = "sum")

maxC <- max(yearlySp@data, na.rm = TRUE)
palBW <- leaflet::colorNumeric(c("white", "navyblue"), 
                               c(0, maxC), 
                               na.color = "transparent")

plot(yearlySp["2005"], col=palBW(yearlySp@data$'2005'), main="2005")
legend("topleft", inset = c(0,0.05),
       legend = round(seq(0, maxC, length.out = 5)),
       col = palBW(seq(0, maxC, length.out = 5)),
       title = "Number of \nobservations", pch = 15, bty="n")
plot(yearlySp["2015"], col=palBW(yearlySp@data$'2015'), main="2015")
legend("topleft", inset = c(0,0.05),
       legend = round(seq(0, maxC, length.out = 5)),
       col = palBW(seq(0, maxC, length.out = 5)),
       title = "Number of \nobservations", pch = 15, bty="n")
par(oldpar)

```

Perhaps one needs to save many summaries over each grid cell.

```{r BIRDSsave, message=FALSE, warning=FALSE, eval=FALSE}

gridSummary <- SB$spatial@data
write.csv(gridSummary, "Callitriche grid summary.csv")

```

One could also think of agreggating the data temporally...

```{r BIRDStemporal, message=FALSE, warning=FALSE}
# There is a summary on SB
SB$temporal$nObs

# But the function exportBIrds() offers planty of combinations
yearlyXTS <- exportBirds(SB, 
                         dimension = "temporal", 
                         timeRes = "yearly", 
                         variable = "nObs",
                         method = "sum")

plot(yearlyXTS, col = "darkblue", 
     grid.ticks.on = "year",  
     grid.col = "lightgrey",  
     main = "Number of observations")

```

<!--chapter:end:01-fish-data.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_knit$set(root.dir = here::here())
set.seed(1)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = FALSE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  out.width = "\\textwidth", 
  fig.align = "center",
  fig.width = 7,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)
options(knitr.kable.NA = "")
options(dplyr.print_min = 6, dplyr.print_max = 6)
```
# The importance of questions and sources of data

## Questions
Any question to be asked of biodiversity data should be put as simply and succinctly as possible. With the number of different subject areas and techniques used, analyses can quickly become complex.

## Taxonomies
It is important to be aware of likely taxonomic anomalies prior to working within a region. Checklists are very important, especially if working over several regions / countries. Whilst there are many things that will automatically look for the validity of a name they do not check for the validity of that species occurrence. For example *Sphagnum auriculatum* and *S. denticulatum* are both valid names. *S. auriculatum* is the currently accepted species in Europe but in the British Isles, Ireland and the Netherlands *s. denticulatum* is the most recorded taxa. Using data from across the European region without acknowledging this disagreement would impact the results of any research undertaken. For taxa which are known to be capable of dispersing great distances (eg birds) this becomes even more difficult especially when using community sourced data.

For Sweden there is an agreed taxonomy for species accesible through [https://www.dyntaxa.se/] and the R library **dyntaxa**.


## Data Sources
Depending on what questions are being asked there are many different resources available. We focus on biodiversity data 

### Biodiversity record data
- Artportalen [https://www.artportalen.se/] - Sweden's data portal for biodiversity data 
- Global Biodiversity Information Facility	[http://www.gbif.org/] - International organization aggregating biodiversity data. Contains data from a mixture of sources; curated collections, community science data, ecological research projects etc. **rgbif, spocc** 
- BioCASE	[https://www.biocase.org/] - A European transnational biodiversity repository
- eBird	[http://ebird.org/content/ebird/] - American database of bird observations **auk, rebird,spocc**
- iNaturalist	http://www.inaturalist.org/ - International community science observation repository **spocc**
- Berkeley ecoengine	[https://ecoengine.berkeley.edu] - Access to UC Berkley's Natural history data **spocc**
- VertNet	[http://vertnet.org/] - vertebrate biodiversity collections **rvert, spocc**
- iDigBio	[https://www.idigbio.org/] - Integrated digitise biodiversity collections **ridigbio**
- OBIS	[http://www.iobis.org/] - Ocean biodiversity information system **robis**
- ALA	[http://www.ala.org.au/] - Atlas of living Australia **ALA4r**
- Neotoma [https://www.neotomadb.org/] Palaeoecology databas **neotoma**
- ...


<!--chapter:end:02-dragonflies-data.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_knit$set(root.dir = here::here())
set.seed(1)
options(digits = 3)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = FALSE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  out.width = "\\textwidth", 
  fig.align = "center",
  fig.width = 7,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)
options(knitr.kable.NA = "")
options(dplyr.print_min = 6, dplyr.print_max = 6)
```
`r if (knitr:::is_html_output()) '
# References {-}
'`

<!--chapter:end:03-references.Rmd-->

